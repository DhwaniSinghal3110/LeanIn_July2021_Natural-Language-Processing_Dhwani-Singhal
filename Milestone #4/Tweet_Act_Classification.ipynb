{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tweet Act Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3k_oAtrSvqW"
      },
      "source": [
        "## Download glove embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhmlBf8ESSKy",
        "outputId": "914cde06-cbec-4986-f821-402e45cafe62"
      },
      "source": [
        "!wget https://gist.githubusercontent.com/bastings/b094de2813da58056a05e8e7950d4ad1/raw/3fbd3976199c2b88de2ae62afc0ecc6f15e6f7ce/glove.840B.300d.sst.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-02 06:56:17--  https://gist.githubusercontent.com/bastings/b094de2813da58056a05e8e7950d4ad1/raw/3fbd3976199c2b88de2ae62afc0ecc6f15e6f7ce/glove.840B.300d.sst.txt\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 53933315 (51M) [text/plain]\n",
            "Saving to: ‘glove.840B.300d.sst.txt’\n",
            "\n",
            "glove.840B.300d.sst 100%[===================>]  51.43M   176MB/s    in 0.3s    \n",
            "\n",
            "2021-09-02 06:56:19 (176 MB/s) - ‘glove.840B.300d.sst.txt’ saved [53933315/53933315]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHu1OkA2THwZ"
      },
      "source": [
        "!cp glove.840B.300d.sst.txt sample_data/glove.840B.300d.sst.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF3lQmoJS1gf"
      },
      "source": [
        "## Importing necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmZj1EqcTmpu"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import re\n",
        "import itertools\n",
        "from collections import Counter\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.optimizers import *\n",
        "from keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import *\n",
        "from keras.preprocessing import sequence\n",
        "from keras.regularizers import *\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import *\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import timeit"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4y7hCAATtTI"
      },
      "source": [
        "## Supporting Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8PSHKX_Txus"
      },
      "source": [
        "def dumpPickle(path,object_to_dump):\n",
        "\tf=open(path,'wb')\n",
        "\tpickle.dump(object_to_dump,f)\n",
        "\tf.close()\n",
        "\n",
        "#Reads an object stores at 'path'\n",
        "def readPickle(path):\n",
        "\tf=open(path,'rb')\n",
        "\tob_to_load=pickle.load(f)\n",
        "\tf.close()\n",
        "\treturn ob_to_load\n",
        "\n",
        "#Loads an embedding matrix stores at emb_pickle_path if doesn't exists a pickled file, then creates One which is initialized by normal distribution with mean and std dev of the embeddings used, if given the option to save it saves\n",
        "#the newly created embedding matrix at saveName\n",
        "def load_create_embedding_matrix(word_index,vocab_size,emb_dim,emb_path,emb_pickle_path=False,save=False,saveName=None):\n",
        "\tif not emb_pickle_path:\n",
        "\t\tembedding_dict={}\n",
        "\t\tf=open(emb_path,'rb')\n",
        "\t\tfor line in f:\n",
        "\t\t\tfields=line.split()\n",
        "\t\t\tword=fields[0]\n",
        "\t\t\tw_e=np.asarray(fields[1:],dtype='float32')\n",
        "\t\t\tembedding_dict[word]=w_e\n",
        "\t\tf.close()\n",
        "\t\tallembs=np.stack(embedding_dict.values())\n",
        "\t\temb_mean,emb_std=allembs.mean(),allembs.std()\n",
        "\t\tembedding_matrix=np.random.normal(emb_mean,emb_std,(vocab_size,emb_dim))\n",
        "\t\tfor word,index in word_index.items():\n",
        "\t\t\t#print(word)\n",
        "\t\t\tvector=embedding_dict.get(word)\n",
        "\t\t\tif vector is not None:\n",
        "\t\t\t\tembedding_matrix[index]=vector\n",
        "\t\tif save:\n",
        "\t\t\tdumpPickle(saveName,embedding_matrix)\n",
        "\telse:\n",
        "\t\tf=open(emb_pickle_path,'rb')\n",
        "\t\tembedding_matrix=pickle.load(f)\n",
        "\t\tf.close()\n",
        "\treturn embedding_matrix\n",
        "\n",
        "\n",
        "#creates a tokenizer from training data file in csv format, if there is one it loads and returns\n",
        "def load_create_tokenizer(train_data,tok_path=None,savetokenizer=False):\n",
        "\tif tok_path == None:\n",
        "\t\ttokenizer=Tokenizer()\n",
        "\t\ttokenizer.fit_on_texts(train_data)\n",
        "\t\tlen(tokenizer.word_index)\n",
        "\t\tif savetokenizer:\n",
        "\t\t\tdumpPickle('./New_Tokenizer.tkn',tokenizer)\n",
        "\telse:\n",
        "\t\ttokenizer=readPickle(tok_path)\n",
        "\treturn tokenizer\n",
        "\n",
        "def load_create_padded_data(X_train,savetokenizer,padPath=None,isPaddingDone=False,maxlen=None,tokenizer_path=None,save_new_padded_data=False,path_for_new_data=False):\n",
        "\t#print(tokenizer_path)\n",
        "\tif not isPaddingDone:\n",
        "\t\ttokenizer=load_create_tokenizer(X_train,tok_path=tokenizer_path,savetokenizer=savetokenizer)\n",
        "\t\t#word_index=tokenizer.word_index\n",
        "\t\tX_train=tokenizer.texts_to_sequences(X_train)\n",
        "\t\tX_train=pad_sequences(X_train,maxlen=maxlen)\n",
        "\t\tif save_new_padded_data:\n",
        "\t\t\tdumpPickle(path_for_new_data,X_train)\n",
        "\telse:\n",
        "\t\tX_train=readPickle(padPath)\n",
        "\treturn X_train"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeiJZtWEUHDw"
      },
      "source": [
        "## loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MRWT8-P3UJaH",
        "outputId": "ca181277-92ec-489d-9b89-82f973376031"
      },
      "source": [
        "data = pd.read_csv('/content/TWEET_DATA_IEEE_TCSS_-_Sheet1.csv') \n",
        "data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RT @Bipartisanism: Katie Couric just schooled #TedCruz on gay marriage in epic fashion. http://t.co/JtNOPqqOug</th>\n",
              "      <th>STM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RT @stevesilberman: If you missed it: Sick bur...</td>\n",
              "      <td>EXP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@jk_rowling &amp; the Never-Ending Story: With a #...</td>\n",
              "      <td>QUE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RT @somebadideas: The emotional &amp; personal eff...</td>\n",
              "      <td>EXP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RT @jk_rowling: A 9-year-old Nigerian girl has...</td>\n",
              "      <td>STM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @jk_rowling: I don't want to say too much m...</td>\n",
              "      <td>EXP</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  RT @Bipartisanism: Katie Couric just schooled #TedCruz on gay marriage in epic fashion. http://t.co/JtNOPqqOug  STM\n",
              "0  RT @stevesilberman: If you missed it: Sick bur...                                                              EXP\n",
              "1  @jk_rowling & the Never-Ending Story: With a #...                                                              QUE\n",
              "2  RT @somebadideas: The emotional & personal eff...                                                              EXP\n",
              "3  RT @jk_rowling: A 9-year-old Nigerian girl has...                                                              STM\n",
              "4  RT @jk_rowling: I don't want to say too much m...                                                              EXP"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aj-kllZtUz8R"
      },
      "source": [
        "## Splitting in 80-20 ratio for test and train "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdCuP3FgU_k2"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train,test = train_test_split(data, test_size=0.2) \n",
        "train=pd.DataFrame(train)\n",
        "train.columns=[\"Tweet\",\"Label\"]\n",
        "test=pd.DataFrame(test)\n",
        "test.columns=[\"Tweet\",\"Label\"]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGYqXBd8VEyQ"
      },
      "source": [
        "train_Text=train[\"Tweet\"]\n",
        "train_label=train[\"Label\"]\n",
        "test_Text=test[\"Tweet\"]\n",
        "test_label=test[\"Label\"]\n",
        "\n",
        "train = [s.strip() for s in train_Text]\n",
        "test = [s.strip() for s in test_Text]\n",
        "\n",
        "text = train + test\n",
        "max1=0\n",
        "\n",
        "#making same length of all text \n",
        "for i in range(0,len(text)):\n",
        "\tdata=text[i].split(\" \")\n",
        "\tmax2=len(data)\n",
        "\tif(max2>max1):\n",
        "\t\tmax1=max2\n",
        "\n",
        "\n",
        "sequence_length = max1"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdGzEoJiVJjb"
      },
      "source": [
        "## Creating padded data and embedding matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNWi67h3VRGi",
        "outputId": "871d7361-b462-4ca1-8592-a81775ee588b"
      },
      "source": [
        "print(\"creating data\")\n",
        "\n",
        "\n",
        "tokenizer=load_create_tokenizer(train,None,True)\n",
        "X_train=load_create_padded_data(X_train=train,savetokenizer=False,isPaddingDone=False,maxlen=sequence_length,tokenizer_path='./New_Tokenizer.tkn')\n",
        "X_test=load_create_padded_data(X_train=test,savetokenizer=False,isPaddingDone=False,maxlen=sequence_length,tokenizer_path='./New_Tokenizer.tkn')\n",
        "word_index=tokenizer.word_index\n",
        "embedding_matrix=load_create_embedding_matrix(word_index,len(word_index)+1,300,'./glove.840B.300d.sst.txt',False,True,'./Emb_Mat.mat')\n",
        "\n",
        "print(\"data created\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "creating data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUCLBQ8fVZe_"
      },
      "source": [
        "## One-hot encode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHbUCZcOVc0Q",
        "outputId": "44e4c17c-24db-4768-c6e1-c92d037d12f4"
      },
      "source": [
        "lbl_dict={}\n",
        "index=0\n",
        "for dial_lbls in train_label:\n",
        "\tif dial_lbls not in lbl_dict:\n",
        "\t\tlbl_dict[dial_lbls]=index\n",
        "\t\tindex=index+1\n",
        "print((lbl_dict))\n",
        "\n",
        "def create_label(label):\n",
        "\t\n",
        "    Y=[]\n",
        "    for i in label:\n",
        "    \txxx=np.zeros(len(lbl_dict)) \n",
        "    \tj=lbl_dict.get(i)\n",
        "    \txxx[j]=1\n",
        "    \tY.append(xxx)\n",
        "    return Y\n",
        "\n",
        "label = train_label\n",
        "Y_train = create_label(label)\n",
        "\n",
        "label = test_label\n",
        "Y_test = create_label(label)\n",
        "\n",
        "y_train=np.array([i for i in Y_train])\n",
        "y_test=np.array([i for i in Y_test])\n",
        "\n",
        "embedding_dim = 300"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'STM': 0, 'OTH': 1, 'EXP': 2, 'THT': 3, 'SUG': 4, 'QUE': 5, 'REQ': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzG72EPbVjwA",
        "outputId": "3cd2b3e6-e840-4d45-f479-1b52525c824d"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5999, 57)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKdHvUWHVmMb",
        "outputId": "0a3d4d4b-588f-4d01-9f14-453ccb841b0c"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1500, 57)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyutBHpCVq3z",
        "outputId": "64978099-d328-40d8-8d0c-ebff5fd0a85f"
      },
      "source": [
        "embedding_matrix.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15188, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aACSPhZV1za"
      },
      "source": [
        "## Creating CNN 1-D Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxWFOi-cV5hg",
        "outputId": "d10fca75-f1af-477c-ab11-41f77fd27a99"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "print(\"Creating Model...\")\n",
        "inputs = Input(shape=(sequence_length,), dtype='int32')\n",
        "embedding = Embedding(input_dim=len(word_index)+1, output_dim=embedding_dim, weights=[embedding_matrix], input_length=sequence_length)(inputs)\n",
        "conv_0 = Conv1D(filters=32, kernel_size=3, padding='same', kernel_initializer='normal', activation='relu')(embedding)\n",
        "maxpool_0 = MaxPooling1D(pool_size=2)(conv_0)\n",
        "dropout = Dropout(0.1)(maxpool_0)\n",
        "conv_1 = Conv1D(filters=32, kernel_size=3, padding='same', kernel_initializer='normal', activation='relu')(dropout)\n",
        "maxpool_1 = MaxPooling1D(pool_size=2)(conv_1)\n",
        "flatten = Flatten()(maxpool_1)\n",
        "predictions = Dense(1000, activation='relu')(flatten)\n",
        "#predictions1 = output layer\n",
        "#Lets assume, correct output => [0,1,0,0,0,0,0,0]; generated output => [0.03, 0.90, 0.01, 0.02, 0.01, 0.01, 0.01, 0.01]\n",
        "predictions1 = Dense(len(lbl_dict), activation='softmax')(predictions)\n",
        "adam = Adam(lr=0.01, decay=0.3)\n",
        "model = Model(inputs=inputs, outputs=predictions1)\n",
        "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=4, batch_size=64, validation_data=(X_test, y_test))\n",
        "\n",
        "\n",
        "predicted=model.predict(X_test)\n",
        "#print(\"DONE\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating Model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "94/94 [==============================] - 9s 87ms/step - loss: 1.5672 - accuracy: 0.5174 - val_loss: 1.3645 - val_accuracy: 0.5293\n",
            "Epoch 2/4\n",
            "94/94 [==============================] - 8s 84ms/step - loss: 1.3482 - accuracy: 0.5304 - val_loss: 1.3414 - val_accuracy: 0.5387\n",
            "Epoch 3/4\n",
            "94/94 [==============================] - 8s 84ms/step - loss: 1.3212 - accuracy: 0.5429 - val_loss: 1.3245 - val_accuracy: 0.5473\n",
            "Epoch 4/4\n",
            "94/94 [==============================] - 8s 84ms/step - loss: 1.3012 - accuracy: 0.5528 - val_loss: 1.3147 - val_accuracy: 0.5513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9q-QXkxBWghj",
        "outputId": "7582f8ae-3d69-440f-9c08-88fc9a43c298"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 57)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_3 (Embedding)      (None, 57, 300)           4556400   \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 57, 32)            28832     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_6 (MaxPooling1 (None, 28, 32)            0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 28, 32)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_7 (Conv1D)            (None, 28, 32)            3104      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_7 (MaxPooling1 (None, 14, 32)            0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 448)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1000)              449000    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 7)                 7007      \n",
            "=================================================================\n",
            "Total params: 5,044,343\n",
            "Trainable params: 5,044,343\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LgK_2TfWnCx"
      },
      "source": [
        "## Evaluate CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1-seDQFWkFF",
        "outputId": "88c9c8c7-a290-40c1-e86a-c9e168ab03c0"
      },
      "source": [
        "Y_predicted=[]\n",
        "for i in predicted:\n",
        "    pos=i.argmax()\n",
        "    Y_predicted.append(pos)\n",
        "    \n",
        "    \n",
        "    \n",
        "Y_test=[]\n",
        "for i in y_test:\n",
        "    pos=i.argmax()\n",
        "    Y_test.append(pos)\n",
        "    \n",
        "from sklearn.metrics import accuracy_score\n",
        "# from sklearn.naive_bayes import GaussianNB\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "# from sklearn.model_selection import cross_val_predict\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(accuracy_score(Y_test, Y_predicted))\n",
        "print(classification_report(Y_test, Y_predicted,digits=4,))\n",
        "print(confusion_matrix(Y_test, Y_predicted))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5513333333333333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5000    0.1555    0.2372       328\n",
            "           1     0.0000    0.0000    0.0000        76\n",
            "           2     0.5551    0.9773    0.7080       794\n",
            "           3     0.0000    0.0000    0.0000        69\n",
            "           4     0.0000    0.0000    0.0000        70\n",
            "           5     0.0000    0.0000    0.0000       120\n",
            "           6     0.0000    0.0000    0.0000        43\n",
            "\n",
            "    accuracy                         0.5513      1500\n",
            "   macro avg     0.1507    0.1618    0.1350      1500\n",
            "weighted avg     0.4032    0.5513    0.4267      1500\n",
            "\n",
            "[[ 51   0 277   0   0   0   0]\n",
            " [  3   0  73   0   0   0   0]\n",
            " [ 18   0 776   0   0   0   0]\n",
            " [ 14   0  55   0   0   0   0]\n",
            " [  8   0  62   0   0   0   0]\n",
            " [  4   0 116   0   0   0   0]\n",
            " [  4   0  39   0   0   0   0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3gJDb3OWwRT"
      },
      "source": [
        "## Bi-LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPgvvAIWWspL",
        "outputId": "654ded13-cc9a-49d2-90ea-3b0943e6685e"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "max_features = 20000  \n",
        "maxlen=200\n",
        "\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
        "x = layers.Embedding(max_features, 72)(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "embedding_4 (Embedding)      (None, None, 72)          1440000   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, None, 128)         70144     \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,609,089\n",
            "Trainable params: 1,609,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZxNW4l8W26A"
      },
      "source": [
        "## Evaluate Bi-LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iB4Y-FLZW82X",
        "outputId": "6f7915c9-3bfc-470b-c72f-5ad126e352a3"
      },
      "source": [
        "Y_predicted=[]\n",
        "for i in predicted:\n",
        "    pos=i.argmax()\n",
        "    Y_predicted.append(pos)\n",
        "    \n",
        "    \n",
        "    \n",
        "Y_test=[]\n",
        "for i in y_test:\n",
        "    pos=i.argmax()\n",
        "    Y_test.append(pos)\n",
        "    \n",
        "    \n",
        "    \n",
        "from sklearn.metrics import accuracy_score\n",
        "# from sklearn.naive_bayes import GaussianNB\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "# from sklearn.model_selection import cross_val_predict\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(accuracy_score(Y_test, Y_predicted))\n",
        "print(classification_report(Y_test, Y_predicted,digits=4,))\n",
        "print(confusion_matrix(Y_test, Y_predicted))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5513333333333333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5000    0.1555    0.2372       328\n",
            "           1     0.0000    0.0000    0.0000        76\n",
            "           2     0.5551    0.9773    0.7080       794\n",
            "           3     0.0000    0.0000    0.0000        69\n",
            "           4     0.0000    0.0000    0.0000        70\n",
            "           5     0.0000    0.0000    0.0000       120\n",
            "           6     0.0000    0.0000    0.0000        43\n",
            "\n",
            "    accuracy                         0.5513      1500\n",
            "   macro avg     0.1507    0.1618    0.1350      1500\n",
            "weighted avg     0.4032    0.5513    0.4267      1500\n",
            "\n",
            "[[ 51   0 277   0   0   0   0]\n",
            " [  3   0  73   0   0   0   0]\n",
            " [ 18   0 776   0   0   0   0]\n",
            " [ 14   0  55   0   0   0   0]\n",
            " [  8   0  62   0   0   0   0]\n",
            " [  4   0 116   0   0   0   0]\n",
            " [  4   0  39   0   0   0   0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRW5tNFbXl1I"
      },
      "source": [
        "# Incorrect samples from the test set and its reasons."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnryD-UecMp9"
      },
      "source": [
        "1. RT @nokatieno: because in Afghanistan a 13 year old girl was shot in    the head for going to school #YesAllWomen \n",
        "       GIVEN: THT     CORRECTION: STM\n",
        "  \n",
        "2. RT @schemaly: Why do girls always fo@to the bathroom together?\" #YesAllWomen are taught necessary buddy systems as girls and are then made\n",
        "       GIVEN: EXP     CORRECTION: STM\n",
        "\n",
        "3. RT @FloraWest: Thought it was time to bring this back: #YesAllWomen http://t.co/oll0yeMQxK\n",
        "       GIVEN: EXP     CORRECTION: THT\n",
        "\n",
        "\n",
        "# Reasons for misclassification\n",
        "\n",
        "1. Synonyms can lead to issues similar to contextual understanding because we use many different words to express the same idea.\n",
        "\n",
        "2. Informal phrases, expressions, idioms, and culture-specific lingo present in various tweets which also changes the meaning of sentence."
      ]
    }
  ]
}